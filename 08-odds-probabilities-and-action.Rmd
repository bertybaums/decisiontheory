# Odds, Probabilities and Actions

We have come to the point where it will no longer be enough to work with our intuitive notion of probability. If we want to go beyond toy decision problems, like the one's we've been covered, and model decisions that are more like the ones we more frequently face, we'll need to have a sufficiently robust understanding of probability. For example, one of the main things we'll want to be able to do is update our beliefs given new information, which effectively amounts to knowing how to update probabilities.

Probabilities are a way of quantifying beliefs. It may seem impossible to measure something as elusive and subjective as beliefs. But some clever conceptual tools have been developed to do just that.

`r newthought("The key idea behind measuring a person's belief")` about the world is to figure out how willing they are to risk things that they care about. To illustrate this idea we're going to momentarily assume that money is our measure of utility.

## Odds and Fair Betting Rates

Here's a roughly general observation of people's behaviour: the more confident someone is that some event is going to happen, the more willing they are to bet. 

Suppose $S$ is some event that Bob and Ally care about. The event might be a sports team winning a game, that it's going to rain tomorrow, that the stock price of some company will be higher by next year, etc. 

Let's say Bob is more than 50% confident that $S$ will happen. In fact, let's suppose that Bob would accept a deal that would pay him $\$1$ if $S$ happens, but would cost him $\$2$ if it doesn't.   Let's say Ally thinks Bob is wrong to be so confident and agrees to take Bob's bet.  In effect, this means that Ally is willing to put $\$1$ on the table for the chance of winning the $\$2$ that Bob is willing to put on the table. The **stake** is the sum of all the money on the table, in this case $\$1 + \$2 = \$3$. Whoever ends up being right gets to take the stake.^[Careful here. If Ally turns out to win because $S$ does not happen, she wins the stake ($\$3$), but since she contributed $\$1$ to it the amount she *gains* is $\$2$.]

`r newthought("Bob's fair betting rate")` can be expressed by dividing his potential loss by the stake:

$$
  \begin{aligned}
    \mbox{Betting Rate} &= \frac{\mbox{Potential Loss}}{\mbox{Stake}}\\
                        &= \frac{\$2}{\$2 + \$1}\\
                        &= \frac{2}{3}.
  \end{aligned}
$$

Bob's betting rate is $2/3$, which is a reflection of how confident he is that $S$ will happen. And here's the next move: that's Bob's personal probability that $S$ will happen, i.e. $Pr_{Bob}(S)=2/3$. 

`r newthought("Bob's fair odds")` is another way that betting is sometimes talked about. To express Bob's fair better rate in terms of odds, we take the ratio of potential loss to potential win:

$$
  \begin{aligned}
    \mbox{Odds} &= \mbox{Potential Loss : Potential Win}\\
                &=  2:1
  \end{aligned}
$$

The odds that Bob would accept are another reflection of his degree of confidence. In fact, there is a handy way of linking up our notion of expected value with odds and probabilities.  

`r newthought("A fair bet")` is one in which the *expected value* is zero. That is, if we weight the potential win by the probability of winning, and we weight the potential loss by the probability of losing, the odds should "cancel out" or "wash out": $$ (2/3)(\$1) + (1/3)(-\$2) = 0. $$ 

Here's a helpful visual way of understanding the idea of a fair bet.  Notice first an inverse relationship between probabilities and payoffs when it comes to risks (especially in gambling): events with really high payoffs tend to have low probabilities, and likewise, the more probable an event is the lower the payoffs tend to be. If the amount of probability is like the width of a rectangle, and the payoff (or loss) is like the height of a rectangle, then a fair bet will be one in which the area of a rectangle that represents Bob winning will have the same amount of area that represents Bob lossing. 

```{r echo=FALSE, cache=TRUE, fig.margin=FALSE, fig.cap="A bet that pays $\\$1$ if Bob wins and costs $\\$2$ if he loses, is fair when the purple and orange regions have equal area: when the probability of winning is $2/3$."}
library(ggplot2)
library(dplyr)
f <- function(x) case_when(x <= 2/3 ~ 1, x <= 1 ~ 0)
g <- function(x) case_when(x <= 2/3 ~ 0, x <= 1 ~ -2)
ggplot() +
  stat_function(fun = f, geom = "area", n = 1000, fill = "darkviolet") +
  stat_function(fun = g, geom = "area", n = 1000, fill = "darkorange") +
  scale_y_continuous("payoff ($)", breaks = seq(-2, 1, 1), limits = c(-2.5, 1.5)) +
  scale_x_continuous("probability", labels = c("0" = "0", "1/3" = "1/3", "2/3" = "2/3", "1" = "1"), breaks = seq(0, 1, 1/3))
```

To be clear, what Bob considers to be a fair bet might change. For example, suppose Bob comes into some information that significantly decreases his confidence that $S$ will happen. Let's say his confidence goes all the way down to 10% (i.e. 1/10). Since his confidence went down, he should be willing to risk less, that is, he should be willing to stake much less. How much less? As a fair bet, Bob will want to make sure that the expected value will be 0: $$ (1/10)(\$9) + (9/10)(-\$1) = 0. $$ So for Bob to be willing make a bet with Ally give this new information, Ally would need to be willing to put at least $\$9$ in the stake for Bob's $\$1$.

Notice how our visualization using rectangles will change for this new scenario, but the two rectangles will still have the same area.

```{r echo=FALSE, cache=TRUE, fig.margin=FALSE, fig.cap="A bet that pays $\\$9$ if Bob wins and costs $\\$1$ if he loses is fair when the probability of winning is $1/10$."}
f <- function(x) case_when(x <= 1/10 ~ 9, x <= 1 ~ 0)
g <- function(x) case_when(x <= 1/10 ~ 0, x <= 1 ~ -1)
ggplot() +
  stat_function(fun = f, geom = "area", n = 1000, fill = "darkviolet") +
  stat_function(fun = g, geom = "area", n = 1000, fill = "darkorange") +
  scale_y_continuous("payoff ($)", limits = c(-1.5, 10.5)) +
  scale_x_continuous("probability")
```


`r newthought("Here's a General Recipe")` for quantifying a person's probability that a proposition $S$ is true using the idea of fair bets:

1. Find a bet on $S$ that they see as fair. Call the potential winnings $W$ and the potential losses $L$.
2. Because the bet is fair to their eyes, set the expected value of the bet equal to zero:
    $$ [Pr(S) \times W] + [(1-\Pr(S)) \times -L] = 0. $$
3. Now solve for $Pr(S)$:
    $$
      \begin{aligned}
        (Pr(S) \times W)  + ((1-Pr(S)) \times -L) &= 0 \\
        (Pr(S) \times W)  + (-L) + (Pr(S) \times L) &= 0 \\
             (Pr(S) \times W) + (Pr(S) \times L) &= L \\
             Pr(S)\times (W + L) &= L \\
                                       Pr(S) &= \frac{L}{W+L}.
      \end{aligned}
    $$

Notice that we have the formula for the fair betting rate again!  It's helpful to memorize this formula so you don't have to do the derivation each time. But more important than that is knowing that there is a recipe for getting from bets to personal probabilities.


## Advantageous Bets

The general recipe we just developed uses the idea of fair bets (or fair odds). The idea here is that a person would be willing to take either side of the bet. Using the language of preferences: the person is *indifferent* between the two options. What happens if betting rates aren't fair in the eyes of Bob? In that case Bob would no longer be indifferent, he would want to take one side!

For example, let's suppose that Bob is confident that $S$ will happen, say by three to two odds, i.e. $Pr(S)=3/5$. That means that, from Bob's perspective, for every $\$2$ that Ally is willing to put in the stake, he is willing to put in $\$3$. That is his fair bet.^[Notice: $(3/5)(\$2) + (2/5)(-\$3) = 0$ ] Now consider two scenarios:

- (Scenario 1) Ally is willing to give Bob even odds, i.e., she is willing to put in $\$3$ for every $\$3$ that Bob puts in the stake (and as before, if $S$ happens then Bob wins the stake). So for the same amount that Bob is willing to lose in *his* fair bet, in this scenario he has the same probability of winning, but now the *payoff* for winning is higher. From Bob's perspective, his expected value is a gain:  $$ (3/5)(\$3) + (2/5)(-\$3) = 0.6 $$. So Ally's offer would favor Bob and is advantageous (in his eyes).

- (Scenario 2) Ally is only will to put in $\$1$ for every $\$3$ that Bob puts in the stake (and as before, if $S$ happens then Bob wins the stake). So in order to win $\$2$ from Ally in this scenario, he would have to be willing to lose $\$6$, which is twice the amount relative to his fair better rate! From Bob's perspective, his expected value is now a loss:  $$ (3/5)(\$1) + (2/5)(-\$3) = -0.6 $$. So here Ally's offer would not be advantageous to Bob.

`r newthought("There's an important lesson here.")` Just because a person is willing to take a bet does not mean that they think it's a fair bet. Like in Scenario 1, Bob is willing to take bets that he perceives as advantageous to him. But in Scenario 2, he would rather be in Ally's shoes! So when we're measuring people's personal probabilities, we have to make sure that the bets that they are willing to take are ones that they think are fair (i.e. the bet, from their perspective, isn't advantageous or disadvantageous).

`r newthought("There's complications though.")` Recall that money doesn't perfectly track utility, it is at best a very rough estimate. In previous chapters we saw how gaining a dollar is not the same as losing a dollar. Moreover, the utility of gaining/losing a dollar depends on how much you already have. 

`r newthought("Another complication")` is that we're assuming that Bob is *following* the expected utility strategy. As we saw in the discussion of paradoxes like the Allais paradox, we have some reason for thinking that people don't follow it. So our way of measuring personal probability isn't perfect, but it's still a significant advancement in measuring something that we initially thought was purely subjective.

`r newthought("But hold on.")` It's not a defect of a camera when it won't take pictures in a dark room. Similarly, if someone isn't following the expected utility formula, that says something about the person, not the method by which we can measure personal probabilities. 

`r newthought("Ought people to behave")` according to the expected utility formula? According to the laws of probability and some assumptions that connect beliefs with actions: yes we should. The arguments here are known as *Dutch Book* arguments. Before we get to these arguments, we need to briefly say at least informally what the laws (or axioms) of probability are.


## The Axioms of Probability

There are three standard axioms of probabilities. I'll present them informally here.

1. (Non-negativity) Probabilities can't be less than zero, i.e., $Pr(S)\geq 0$.

1. (Normality) If we sum up the probabilities of *all* possible events, we get 1. For example, if *all* the possible events for tomorrow are Rainy, Cloudy, and Sunny, then the probability that tomorrow is Rainy or Cloudy or Sunny is 1. Another example: if *all* the possible winners in the race are numbered 1 through 7, then the probability that one of them wins is 1.

1. (Finite Additivity) For mutually exclusive events, their disjunction is additive. For example, 

?show some bets that aren't worth taking to illustrate what's coming in the more technical chapter next?
