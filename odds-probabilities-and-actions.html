<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 8 Odds, Probabilities and Actions | Decision Theory" />
<meta property="og:type" content="book" />

<meta property="og:description" content="This is a draft of a decision theory book written in BookDown" />
<meta name="github-repo" content="bertybaums/decisiontheory" />

<meta name="author" content="Bert Baumgaertner" />

<meta name="date" content="2022-11-01" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<meta name="description" content="This is a draft of a decision theory book written in BookDown">

<title>Chapter 8 Odds, Probabilities and Actions | Decision Theory</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />





<link rel="stylesheet" href="toc-vip.css" type="text/css" />
<link rel="stylesheet" href="custom.css" type="text/css" />

</head>

<body>


<div style="display: none;">
$$
  \definecolor{bookorange}{RGB}{255,140,0}
  \definecolor{bookblue}{RGB}{0,92,169}
  \definecolor{bookpurple}{RGB}{148,0,211}
$$
</div>

<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface-and-prerequisites">Preface and Prerequisites</a><ul>
<li><a href="index.html#what-is-a-conceptual-introduction"><span class="toc-section-number">0.1</span> What is a conceptual introduction?</a></li>
<li><a href="index.html#how-to-read-a-table-or-matrix"><span class="toc-section-number">0.2</span> How to read a table or matrix</a></li>
<li><a href="index.html#the-very-basic-math"><span class="toc-section-number">0.3</span> The Very Basic Math</a></li>
<li><a href="index.html#inspiration-and-acknowledgments"><span class="toc-section-number">0.4</span> Inspiration and Acknowledgments</a></li>
</ul></li>
<li class="has-sub"><a href="intro.html#intro"><span class="toc-section-number">1</span> Introduction</a><ul>
<li><a href="intro.html#some-basic-conceptual-ingredients"><span class="toc-section-number">1.1</span> Some Basic Conceptual Ingredients</a></li>
<li><a href="intro.html#rationality---the-descriptive-and-normative"><span class="toc-section-number">1.2</span> Rationality - the Descriptive and Normative</a></li>
<li><a href="intro.html#uncertainty"><span class="toc-section-number">1.3</span> Uncertainty</a></li>
<li><a href="intro.html#practical-and-theoretical-problems"><span class="toc-section-number">1.4</span> Practical and Theoretical Problems</a></li>
<li><a href="intro.html#summary"><span class="toc-section-number">1.5</span> Summary</a></li>
<li><a href="intro.html#exercises">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="ranking.html#ranking"><span class="toc-section-number">2</span> Ranking</a><ul>
<li><a href="ranking.html#maximin-and-maximax"><span class="toc-section-number">2.1</span> Maximin and Maximax</a></li>
<li><a href="ranking.html#the-dominance-principle"><span class="toc-section-number">2.2</span> The Dominance Principle</a></li>
<li><a href="ranking.html#more-than-two-options-and-two-states"><span class="toc-section-number">2.3</span> More than two options and two states</a></li>
<li><a href="ranking.html#non-unique-recommendations"><span class="toc-section-number">2.4</span> Non-Unique Recommendations</a></li>
<li><a href="ranking.html#independence-of-options-and-states"><span class="toc-section-number">2.5</span> Independence of Options and States</a></li>
<li><a href="ranking.html#exercises-1">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="transitivity-and-completeness.html#transitivity-and-completeness"><span class="toc-section-number">3</span> Transitivity and Completeness</a><ul>
<li><a href="transitivity-and-completeness.html#notation"><span class="toc-section-number">3.1</span> Notation</a></li>
<li><a href="transitivity-and-completeness.html#money-pump-arguments-for-axioms"><span class="toc-section-number">3.2</span> Money Pump Arguments for Axioms</a></li>
<li><a href="transitivity-and-completeness.html#arguments-for-transitivity"><span class="toc-section-number">3.3</span> Arguments for Transitivity</a></li>
<li><a href="transitivity-and-completeness.html#arguments-for-completeness"><span class="toc-section-number">3.4</span> Arguments for Completeness</a></li>
<li><a href="transitivity-and-completeness.html#social-choice"><span class="toc-section-number">3.5</span> Social Choice</a></li>
<li><a href="transitivity-and-completeness.html#limitations-and-key-take-aways"><span class="toc-section-number">3.6</span> Limitations and Key Take Aways</a></li>
<li><a href="transitivity-and-completeness.html#exercises-2">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="utilities.html#utilities"><span class="toc-section-number">4</span> Utilities</a><ul>
<li><a href="utilities.html#creating-an-interval-scale"><span class="toc-section-number">4.1</span> Creating an Interval Scale</a></li>
<li><a href="utilities.html#what-do-the-numbers-mean"><span class="toc-section-number">4.2</span> What do the numbers mean?</a></li>
<li><a href="utilities.html#applications-and-challenges"><span class="toc-section-number">4.3</span> Applications and Challenges</a></li>
<li><a href="utilities.html#more-challenges-and-final-remarks"><span class="toc-section-number">4.4</span> More Challenges and Final Remarks</a></li>
<li><a href="utilities.html#exercises-3">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="expected-utilities.html#expected-utilities"><span class="toc-section-number">5</span> Expected Utilities</a><ul>
<li><a href="expected-utilities.html#expected-utility-by-example"><span class="toc-section-number">5.1</span> Expected Utility by Example</a></li>
<li><a href="expected-utilities.html#meu-maximize-expected-utility-strategy"><span class="toc-section-number">5.2</span> (MEU) Maximize Expected Utility Strategy</a></li>
<li><a href="expected-utilities.html#application-combining-meu-and-the-multi-attribute-approach"><span class="toc-section-number">5.3</span> Application: Combining MEU and the Multi-Attribute Approach</a></li>
<li><a href="expected-utilities.html#pascals-wager"><span class="toc-section-number">5.4</span> Pascal’s Wager</a></li>
<li><a href="expected-utilities.html#key-take-aways"><span class="toc-section-number">5.5</span> Key Take Aways</a></li>
<li><a href="expected-utilities.html#exercises-4">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="arguments-about-meu.html#arguments-about-meu"><span class="toc-section-number">6</span> Arguments about MEU</a><ul>
<li><a href="arguments-about-meu.html#the-domain-of-meu"><span class="toc-section-number">6.1</span> The Domain of MEU</a></li>
<li><a href="arguments-about-meu.html#long-run-arguments-for-meu"><span class="toc-section-number">6.2</span> Long Run Arguments for MEU</a></li>
<li><a href="arguments-about-meu.html#two-kinds-of-arguments-against-meu"><span class="toc-section-number">6.3</span> Two Kinds of Arguments Against MEU</a></li>
<li><a href="arguments-about-meu.html#arguments-against-normative-meu"><span class="toc-section-number">6.4</span> Arguments Against Normative MEU</a></li>
<li><a href="arguments-about-meu.html#arguments-against-descriptive-meu"><span class="toc-section-number">6.5</span> Arguments Against Descriptive MEU</a></li>
<li><a href="arguments-about-meu.html#summary-1"><span class="toc-section-number">6.6</span> Summary</a></li>
<li><a href="arguments-about-meu.html#exercises-5"><span class="toc-section-number">6.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="intervention.html#intervention"><span class="toc-section-number">7</span> Intervention</a><ul>
<li><a href="intervention.html#causal-models"><span class="toc-section-number">7.1</span> Causal Models</a></li>
<li><a href="intervention.html#common-causes"><span class="toc-section-number">7.2</span> Common Causes</a></li>
<li><a href="intervention.html#application-to-newcomb-like-problems"><span class="toc-section-number">7.3</span> Application to Newcomb-like Problems</a></li>
<li><a href="intervention.html#the-locus-of-choice-and-types-of-decision-theories"><span class="toc-section-number">7.4</span> The Locus of Choice and Types of Decision Theories</a></li>
<li><a href="intervention.html#exercises-6">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="odds-probabilities-and-actions.html#odds-probabilities-and-actions"><span class="toc-section-number">8</span> Odds, Probabilities and Actions</a><ul>
<li><a href="odds-probabilities-and-actions.html#odds-and-fair-betting-rates"><span class="toc-section-number">8.1</span> Odds and Fair Betting Rates</a></li>
<li><a href="odds-probabilities-and-actions.html#advantageous-bets"><span class="toc-section-number">8.2</span> Advantageous Bets</a></li>
<li><a href="odds-probabilities-and-actions.html#the-axioms-of-probability-and-dutchbooks"><span class="toc-section-number">8.3</span> The Axioms of Probability and Dutchbooks</a></li>
<li><a href="odds-probabilities-and-actions.html#application"><span class="toc-section-number">8.4</span> Application</a></li>
<li><a href="odds-probabilities-and-actions.html#exercises-7">Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="probabilities-and-logic.html#probabilities-and-logic"><span class="toc-section-number">9</span> Probabilities and Logic</a><ul>
<li><a href="probabilities-and-logic.html#measures"><span class="toc-section-number">9.1</span> Measures</a></li>
<li><a href="probabilities-and-logic.html#normalized-measures"><span class="toc-section-number">9.2</span> Normalized Measures</a></li>
<li><a href="probabilities-and-logic.html#possibilities-and-truth-tables"><span class="toc-section-number">9.3</span> Possibilities and Truth Tables</a></li>
<li><a href="probabilities-and-logic.html#independence"><span class="toc-section-number">9.4</span> Independence</a></li>
<li><a href="probabilities-and-logic.html#summary-2"><span class="toc-section-number">9.5</span> Summary</a></li>
<li><a href="probabilities-and-logic.html#exercises-8"><span class="toc-section-number">9.6</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="conditional-probabilities-and-likelihoods.html#conditional-probabilities-and-likelihoods"><span class="toc-section-number">10</span> Conditional Probabilities and Likelihoods</a><ul>
<li><a href="conditional-probabilities-and-likelihoods.html#calculating-conditional-probability"><span class="toc-section-number">10.1</span> Calculating Conditional Probability</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#application-monty-hall-problem"><span class="toc-section-number">10.2</span> Application: Monty Hall Problem</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#independence-1"><span class="toc-section-number">10.3</span> Independence</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#likelihoods"><span class="toc-section-number">10.4</span> Likelihoods</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#application-the-taxi-cab-problem"><span class="toc-section-number">10.5</span> Application: The Taxi Cab Problem</a></li>
<li><a href="conditional-probabilities-and-likelihoods.html#exercises-9"><span class="toc-section-number">10.6</span> Exercises</a></li>
</ul></li>
<li><a href="base-rates-priors-and-bayes-rule.html#base-rates-priors-and-bayes-rule"><span class="toc-section-number">11</span> Base Rates, Priors, and Bayes Rule</a></li>
<li><a href="learning-and-motivated-reasoning.html#learning-and-motivated-reasoning"><span class="toc-section-number">12</span> Learning and Motivated Reasoning</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="odds-probabilities-and-actions" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Odds, Probabilities and Actions</h1>
<p>We have come to the point where it will no longer be enough to work with our intuitive notion of probability. If we want to go beyond toy decision problems, like the one’s we’ve been covered, and model decisions that are more like the ones we more frequently face, we’ll need to have a sufficiently robust understanding of probability. For example, one of the main things we’ll want to be able to do is update our beliefs given new information, which effectively amounts to knowing how to update probabilities.</p>
<p>Probabilities are a way of quantifying beliefs. It may seem impossible to measure something as elusive and subjective as beliefs. But some clever conceptual tools have been developed to do just that.</p>
<p><span class="newthought">The key idea behind measuring a person’s belief</span> about the world is to figure out how willing they are to risk things that they care about. To illustrate this idea we’re going to momentarily assume that money is our measure of utility.</p>
<div id="odds-and-fair-betting-rates" class="section level2">
<h2><span class="header-section-number">8.1</span> Odds and Fair Betting Rates</h2>
<p>Here’s a roughly general observation of people’s behaviour: the more confident someone is that some event is going to happen, the more willing they are to bet.</p>
<p>Suppose <span class="math inline">\(S\)</span> is some event that Bob and Ally care about. The event might be a sports team winning a game, that it’s going to rain tomorrow, that the stock price of some company will be higher by next year, etc.</p>
<p>Let’s say Bob is more than 50% confident that <span class="math inline">\(S\)</span> will happen. In fact, let’s suppose that Bob would accept a deal that would pay him <span class="math inline">\(\$1\)</span> if <span class="math inline">\(S\)</span> happens, but would cost him <span class="math inline">\(\$2\)</span> if it doesn’t. Let’s say Ally thinks Bob is wrong to be so confident and agrees to take Bob’s bet. In effect, this means that Ally is willing to put <span class="math inline">\(\$1\)</span> on the table for the chance of winning the <span class="math inline">\(\$2\)</span> that Bob is willing to put on the table. The <strong>stake</strong> is the sum of all the money on the table, in this case <span class="math inline">\(\$1 + \$2 = \$3\)</span>. Whoever ends up being right gets to take the stake.<label for="tufte-sn-79" class="margin-toggle sidenote-number">79</label><input type="checkbox" id="tufte-sn-79" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">79</span> Careful here. If Ally turns out to win because <span class="math inline">\(S\)</span> does not happen, she wins the stake (<span class="math inline">\(\$3\)</span>), but since she contributed <span class="math inline">\(\$1\)</span> to it the amount she <em>gains</em> is <span class="math inline">\(\$2\)</span>.</span></p>
<p><span class="newthought">Bob’s fair betting rate</span> can be expressed by dividing his potential loss by the stake:</p>
<p><span class="math display">\[
  \begin{aligned}
    \mbox{Betting Rate} &amp;= \frac{\mbox{Potential Loss}}{\mbox{Stake}}\\
                        &amp;= \frac{\$2}{\$2 + \$1}\\
                        &amp;= \frac{2}{3}.
  \end{aligned}
\]</span></p>
<p>Bob’s betting rate is <span class="math inline">\(2/3\)</span>, which is a reflection of how confident he is that <span class="math inline">\(S\)</span> will happen. And here’s the next move: that’s Bob’s personal probability that <span class="math inline">\(S\)</span> will happen, i.e. <span class="math inline">\(Pr_{Bob}(S)=2/3\)</span>.</p>
<p><span class="newthought">Bob’s fair odds</span> is another way that betting is sometimes talked about. To express Bob’s fair better rate in terms of odds, we take the ratio of potential loss to potential win:</p>
<p><span class="math display">\[
  \begin{aligned}
    \mbox{Odds} &amp;= \mbox{Potential Loss : Potential Win}\\
                &amp;=  2:1
  \end{aligned}
\]</span></p>
<p>The odds that Bob would accept are another reflection of his degree of confidence. In fact, there is a handy way of linking up our notion of expected value with odds and probabilities.</p>
<p><span class="newthought">A fair bet</span> is one in which the <em>expected value</em> is zero. That is, if we weight the potential win by the probability of winning, and we weight the potential loss by the probability of losing, the odds should “cancel out” or “wash out”: <span class="math display">\[ (2/3)(\$1) + (1/3)(-\$2) = 0. \]</span></p>
<p>Here’s a helpful visual way of understanding the idea of a fair bet. Notice first an inverse relationship between probabilities and payoffs when it comes to risks (especially in gambling): events with really high payoffs tend to have low probabilities, and likewise, the more probable an event is the lower the payoffs tend to be. If the amount of probability is like the width of a rectangle, and the payoff (or loss) is like the height of a rectangle, then a fair bet will be one in which the area of a rectangle that represents Bob winning will have the same amount of area that represents Bob lossing.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-19"></span>
<p class="caption marginnote shownote">
Figure 8.1: A bet that pays <span class="math inline">\(\$1\)</span> if Bob wins and costs <span class="math inline">\(\$2\)</span> if he loses, is fair when the purple and orange regions have equal area: when the probability of winning is <span class="math inline">\(2/3\)</span>.
</p>
<img src="decisiontheory_files/figure-html/unnamed-chunk-19-1.png" alt="A bet that pays $\$1$ if Bob wins and costs $\$2$ if he loses, is fair when the purple and orange regions have equal area: when the probability of winning is $2/3$." width="672"  />
</div>
<p>To be clear, what Bob considers to be a fair bet might change. For example, suppose Bob comes into some information that significantly decreases his confidence that <span class="math inline">\(S\)</span> will happen. Let’s say his confidence goes all the way down to 10% (i.e. 1/10). Since his confidence went down, he should be willing to risk less, that is, he should be willing to stake much less. How much less? As a fair bet, Bob will want to make sure that the expected value will be 0: <span class="math display">\[ (1/10)(\$9) + (9/10)(-\$1) = 0. \]</span> So for Bob to be willing make a bet with Ally give this new information, Ally would need to be willing to put at least <span class="math inline">\(\$9\)</span> in the stake for Bob’s <span class="math inline">\(\$1\)</span>.</p>
<p>Notice how our visualization using rectangles will change for this new scenario, but the two rectangles will still have the same area.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-20"></span>
<p class="caption marginnote shownote">
Figure 8.2: A bet that pays <span class="math inline">\(\$9\)</span> if Bob wins and costs <span class="math inline">\(\$1\)</span> if he loses is fair when the probability of winning is <span class="math inline">\(1/10\)</span>.
</p>
<img src="decisiontheory_files/figure-html/unnamed-chunk-20-1.png" alt="A bet that pays $\$9$ if Bob wins and costs $\$1$ if he loses is fair when the probability of winning is $1/10$." width="672"  />
</div>
<p><span class="newthought">Here’s a General Recipe</span> for quantifying a person’s probability that a proposition <span class="math inline">\(S\)</span> is true using the idea of fair bets:</p>
<ol style="list-style-type: decimal">
<li>Find a bet on <span class="math inline">\(S\)</span> that they see as fair. Call the potential winnings <span class="math inline">\(W\)</span> and the potential losses <span class="math inline">\(L\)</span>.</li>
<li>Because the bet is fair to their eyes, set the expected value of the bet equal to zero:
<span class="math display">\[ [Pr(S) \times W] + [(1-\Pr(S)) \times -L] = 0. \]</span></li>
<li>Now solve for <span class="math inline">\(Pr(S)\)</span>:
<span class="math display">\[
   \begin{aligned}
     (Pr(S) \times W)  + ((1-Pr(S)) \times -L) &amp;= 0 \\
     (Pr(S) \times W)  + (-L) + (Pr(S) \times L) &amp;= 0 \\
          (Pr(S) \times W) + (Pr(S) \times L) &amp;= L \\
          Pr(S)\times (W + L) &amp;= L \\
                                    Pr(S) &amp;= \frac{L}{W+L}.
   \end{aligned}
 \]</span></li>
</ol>
<p>Notice that we have the formula for the fair betting rate again! It’s helpful to memorize this formula so you don’t have to do the derivation each time. But more important than that is knowing that there is a recipe for getting from bets to personal probabilities.</p>
</div>
<div id="advantageous-bets" class="section level2">
<h2><span class="header-section-number">8.2</span> Advantageous Bets</h2>
<p>The general recipe we just developed uses the idea of fair bets (or fair odds). The idea here is that a person would be willing to take either side of the bet. Using the language of preferences: the person is <em>indifferent</em> between the two options. What happens if betting rates aren’t fair in the eyes of Bob? In that case Bob would no longer be indifferent, he would want to take one side!</p>
<p>For example, let’s suppose that Bob is confident that <span class="math inline">\(S\)</span> will happen, say by three to two odds, i.e. <span class="math inline">\(Pr(S)=3/5\)</span>. That means that, from Bob’s perspective, for every <span class="math inline">\(\$2\)</span> that Ally is willing to put in the stake, he is willing to put in <span class="math inline">\(\$3\)</span>. That is his fair bet.<label for="tufte-sn-80" class="margin-toggle sidenote-number">80</label><input type="checkbox" id="tufte-sn-80" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">80</span> Notice: <span class="math inline">\((3/5)(\$2) + (2/5)(-\$3) = 0\)</span> </span> Now consider two scenarios:</p>
<ul>
<li><p>(Scenario 1) Ally is willing to give Bob even odds, i.e., she is willing to put in <span class="math inline">\(\$3\)</span> for every <span class="math inline">\(\$3\)</span> that Bob puts in the stake (and as before, if <span class="math inline">\(S\)</span> happens then Bob wins the stake). So for the same amount that Bob is willing to lose in <em>his</em> fair bet, in this scenario he has the same probability of winning, but now the <em>payoff</em> for winning is higher. From Bob’s perspective, his expected value is a gain: <span class="math display">\[ (3/5)(\$3) + (2/5)(-\$3) = 0.6 \]</span> So Ally’s offer would favor Bob and is advantageous (in his eyes).</p></li>
<li><p>(Scenario 2) Ally is only willing to put in <span class="math inline">\(\$1\)</span> for every <span class="math inline">\(\$3\)</span> that Bob puts in the stake (and as before, if <span class="math inline">\(S\)</span> happens then Bob wins the stake). So in order to win <span class="math inline">\(\$2\)</span> from Ally in this scenario, he would have to be willing to lose <span class="math inline">\(\$6\)</span>, which is twice the amount relative to his fair better rate! From Bob’s perspective, his expected value is now a loss: <span class="math display">\[ (3/5)(\$1) + (2/5)(-\$3) = -0.6 \]</span> So here Ally’s offer would not be advantageous to Bob.</p></li>
</ul>
<p><span class="newthought">There’s an important lesson here.</span> Just because a person is willing to take a bet does not mean that they think it’s a fair bet. Like in Scenario 1, Bob is willing to take bets that he perceives as advantageous to him. But in Scenario 2, he would rather be in Ally’s shoes! So when we’re measuring people’s personal probabilities, we have to make sure that the bets that they are willing to take are ones that they think are fair (i.e. the bet, from their perspective, isn’t advantageous or disadvantageous).</p>
<p><span class="newthought">There’s complications though.</span> Recall that money doesn’t perfectly track utility, it is at best a very rough estimate. In previous chapters we saw how gaining a dollar is not the same as losing a dollar. Moreover, the utility of gaining/losing a dollar depends on how much you already have.</p>
<p><span class="newthought">Another complication</span> is that we’re assuming that Bob is <em>following</em> the expected utility strategy. As we saw in the discussion of paradoxes like the Allais paradox, we have some reason for thinking that people don’t follow it. So our way of measuring personal probability isn’t perfect, but it’s still a significant advancement in measuring something that we initially thought was purely subjective.</p>
<p><span class="newthought">But hold on.</span> It’s not a defect of a camera when it won’t take pictures in a dark room. Similarly, if someone isn’t following the expected utility formula, that says something about the person, not the method by which we can measure personal probabilities.</p>
<p><span class="newthought">Ought people to behave</span> according to the expected utility formula? According to the laws of probability and some assumptions that connect beliefs with actions: yes we should. The arguments here are known as <em>Dutch Book</em> arguments. Before we get to these arguments, we need to briefly say at least informally what the laws (or axioms) of probability are.</p>
</div>
<div id="the-axioms-of-probability-and-dutchbooks" class="section level2">
<h2><span class="header-section-number">8.3</span> The Axioms of Probability and Dutchbooks</h2>
<p>There are three standard axioms of probabilities. I’ll present them informally here.</p>
<ol style="list-style-type: decimal">
<li><p>(Non-negativity) Probabilities can’t be less than zero, i.e., <span class="math inline">\(P(S)\geq 0\)</span>.</p></li>
<li><p>(Normality) If we sum up the probabilities of <em>all</em> possible events, we get 1. For example, if <em>all</em> the possible events for tomorrow are Rainy, Cloudy, and Sunny, then the probability that tomorrow is Rainy or Cloudy or Sunny is 1. Another example: if <em>all</em> the possible winners in the race are numbered 1 through 7, then the probability that one of them wins is 1.</p></li>
<li><p>(Finite Additivity) For mutually exclusive events, their disjunction is additive. For example, suppose there’s a horse race with four horses: Gumption, Gallifray, Tungsten, and Shadow. If one horse wins, all the others lose (i.e., horse winnings are exclusive events). So, if the probability of Shadow winning is 0.1, and the probably of Tungsten winning is 0.2, then the probability of Shadow or Tungsten winning is 0.3.</p></li>
</ol>
<p>When we identify axioms of a theory, we can use those axioms to define other constraints or features of the theory. For example, we can define the probability for the negation of a proposition (i.e. that an event will not occur), <span class="math inline">\(\neg X\)</span> as:
<span class="math display">\[
P(\neg X) = 1 - P(X)
\]</span>
As we’ve seen above, that means that fixing the probability of a proposition automatically fixes the probability of its negation (and vice versa). For example, if <span class="math inline">\(P(X)=0.7\)</span> then <span class="math inline">\(P(\neg X)=0.3\)</span>.</p>
<p>This is a helpful feature. Suppose, for example, that we have a lottery with 100 tickets. Each ticket is picked out by a proposition, <span class="math inline">\(X_1, X_2, \ldots, X_{100}\)</span>. The probability of wining a given ticket, <span class="math inline">\(X_i\)</span> is
<span class="math display">\[
P(X_i)=\frac{1}{100}=0.01
\]</span>
Since we have fixed the probability that <span class="math inline">\(X_i\)</span> is true, this automatically fixes the probability that it is false, or equivalently, that <span class="math inline">\(\neg X_i\)</span> is true. Formally,
<span class="math display">\[
P(\neg X_i) = 1-0.01 = 0.99
\]</span></p>
<p>This next claim builds on some logic that we will get to shortly, but it’s worth making explicit now as it will play a central role in the argument in the next section. Consider the exhaustive disjunction of all mutually exclusive propositions (e.g., we think about ALL the lottery tickets, and the rule is that when you win with ticket <span class="math inline">\(X_i\)</span> that means the other tickets did not win). This exhaustive and mutually exclusive disjunction will be a tautology. In our lottery example:
<span class="math display">\[
P(X_1 \vee X_2 \vee \ldots \vee X_{100}) = 1
\]</span></p>
<p>In short, even if there is more than one event that we’re considering, the probabilities of all events have to sum to 1.<label for="tufte-sn-81" class="margin-toggle sidenote-number">81</label><input type="checkbox" id="tufte-sn-81" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">81</span> We’are assuming that the events are mutually exclusive and exhaustive.</span></p>
<p><span class="newthought">The Dutchbook Argument</span> says that you should accept the above three axioms of probability because if you don’t then you allow for the possibility of guaranteed loses of ``fair bets’’ - bets that rationality suggests would not be fair at all, but you would be unable to provide reasons for not accepting them.<label for="tufte-sn-82" class="margin-toggle sidenote-number">82</label><input type="checkbox" id="tufte-sn-82" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">82</span> The person that does accept the three axioms of probability can say why the bets are not fair because they violate one or more of the axioms.</span></p>
<p>The Dutchbook argument can be stated formally, but it’s enough for our purposes to illustrate the argument using the popular example of horse racing. The following table lists all the names of four horses in a race, including the odds and the implied probability of each horse winning. In addition, the table lists the cost of a bet and the corresponding payout if the horse wins.</p>
<table>
<thead>
<tr class="header">
<th align="center">Horse</th>
<th align="center">Odds</th>
<th align="center">Implied.Prob</th>
<th align="center">Bet</th>
<th align="center">Payout</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Gumption</td>
<td align="center">1:1</td>
<td align="center">0.5</td>
<td align="center">$100</td>
<td align="center">$100</td>
</tr>
<tr class="even">
<td align="center">Gallifray</td>
<td align="center">3:1</td>
<td align="center">0.25</td>
<td align="center">$50</td>
<td align="center">$150</td>
</tr>
<tr class="odd">
<td align="center">Tungsten</td>
<td align="center">4:1</td>
<td align="center">0.2</td>
<td align="center">$40</td>
<td align="center">$160</td>
</tr>
<tr class="even">
<td align="center">Shadow</td>
<td align="center">9:1</td>
<td align="center">0.1</td>
<td align="center">$20</td>
<td align="center">$180</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">TOTALS</td>
<td align="center"></td>
<td align="center">1.05</td>
<td align="center">$210</td>
<td align="center">$200</td>
</tr>
</tbody>
</table>
<p>Here’s what to notice from this table. Suppose you’re the bookie and you get one person to bet for each horse. No matter which horse ends up winning, you as the bookie will pay out $200 from the stake (the sum of the bets you received). But if we look at the total that makes up the stake, that total is $210. The means as the bookie you are  to make $10 on the race.</p>
<p>In point of fact, this is how real races are typically organized - and this is a way for you to calculate how much is being “skimmed off the top”. For the most part this isn’t really an issue because we’re willing to let some amount of money to go to those who are organizing the event. But let’s put aside those types of considerations and think instead of a set of bets that you and your friends would set up that is regarded as fair, i.e., that there is no way for someone to scheme and guarantee that they win some money. Each of you in the group has the chance of losing or winning and no one is “skimming off the top”.</p>
<p>Looking at the table again with this in mind, which of the probability axioms is being violated? Recall that the probability of the exhaustive and mutually exclusive disjunction of the options should sum to 1, but the total in the above table is 1.05. This is a violation of Normality.</p>
<p><span class="newthought">A violation of Normality</span> where the sum of probabilities is larger than 1 is good for a bookie because it guarantees they earn money.</p>
<p><span class="newthought">But a violation of Normality</span> where the sum of probabilities is smaller than 1 is bad for the bookie, but good for the gamblers! Suppose, for example, that Shadow withdraws from the race. Now the implied probabilities sum up to 0.95. If now a gambler bets on all the remaining horses (but saves $20 because they don’t bet on Shadow), the gambler is guaranteed to make a profit of $10. As you can imagine, this rarely happens in real life, as bookies are quick to adjust their betting offers to reflect these sorts of changes.</p>
<p>The point of the Dutchbook argument is to get you to appreciate that if you think about probabilities in a way that does not respect the three axioms, you are at risk of being put in a position where you are guaranteed to lose. Of course lots of decisions under uncertainty have the possibility of losing - that’s simply the nature of risk. But those decisions also typically offer the possibilities of gains - that’s why we might be interested in such decisions in the first place. What the Dutchbook argument says is that if you violate any of the three axioms, then included in the decisions you should be willing to accept are decisions where there is a guaranteed loss. It is thought that no coherent account of rationality should find this acceptable. Moreover, such situations are easily avoided by someone who accepts the probability axioms, because the axioms provide them with a reason to reject such decision offers.</p>
<p>If we’re convinced by the Dutchbook argument, which means we agree that we should be striving to think about probabilities as prescribed by the axioms, then this puts serious pressure on the idea that Prospect Theory is a viable approach to capturing a more “human” kind of rationality. Recall that in response to weighting effects, where people treat outcomes with low probabilities differently than outcomes with high probabilities, Prospect Theory proposed a different function to capture how people reason across these contexts. Such a function explicitly deviates from probability theory. Perhaps as a purely descriptive theory that attempts to capture the systematic ways that people go wrong, this is fine. But it would be misleading to think of that account as closer to “human” rationality. After all, we have the capacity to acknowledge the Dutchbook argument. To this extent, at least when we are sober and closer to the better versions of ourselves, we have the capacity to reason according to probability theory.</p>
</div>
<div id="application" class="section level2">
<h2><span class="header-section-number">8.4</span> Application</h2>
<p>Examples from gambling help establish connections between probabilities and our levels of confidence through the idea of odds. In many real world applications, however, the probabilities of outcomes are not as neat as they are in the case of gambling. Nevertheless, it is possible to get some approximations; that is a large part of what the field of statistics is about. We will not go into such details here. But it is worth showing how we can connect some of the concepts so far, and motivate by example what will spell out more abstractly in the next chapter.</p>
<p>Let’s use an example where we estimate some probabilities from frequency data, something that has important ties with medicine and epidemiology. In the context of health it is common to represent data in the form of what is called a <em>two by two table</em> (or 2x2 table). The idea is to use the rows to represent “the exposed” options, like smoking or not smoking, or like using a hand cream or not using a hand cream. The columns represent “the diseased” and “not diseased” which in our case is “rash continues” and “rash gets better”.<label for="tufte-sn-83" class="margin-toggle sidenote-number">83</label><input type="checkbox" id="tufte-sn-83" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">83</span> In the smoking scenario the columns could be “hypertension’’ and”without hypertension’’ for example.</span></p>
<p>Here’s an example of what such data might look like. We’re supposing that each cell represents the number of participants in a study that met the pair of conditions. For example, there are 223 subjects that used the hand cream and had the rash get better. There are 107 subjects that didn’t use the hand cream, but the rash got better anyway. In total there are 330 subjects who’s rash got better. The cells under “Rash Continues” is read similarly. Notice that the cell in the most bottom right corner is the total number of subjects in this study: 426.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Rash Gets Better (R)</th>
<th align="center">Rash Continues (nR)</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Used Cream (C)</td>
<td align="center">223</td>
<td align="center">75</td>
<td align="center">298</td>
</tr>
<tr class="even">
<td align="center">Didn’t Use (nC)</td>
<td align="center">107</td>
<td align="center">21</td>
<td align="center">128</td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center">330</td>
<td align="center">96</td>
<td align="center">426</td>
</tr>
</tbody>
</table>
<p>Suppose we asked what the probability is that someone in our sample used the hand cream.<label for="tufte-sn-84" class="margin-toggle sidenote-number">84</label><input type="checkbox" id="tufte-sn-84" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">84</span> Note that this question is restricted to the sample, the subjects that were in the study. If we want to make claims about the larger population (people not in the sample), we’d have to deploy some inferential statistical tools that we have not covered.</span> To calculate that, we would take the total number of people that use the hand cream (298) and divide that number by the total number of subjects (426). This gives us <span class="math inline">\(298/426=0.6995\)</span> (rounded to four decimal places). Similarly, we can calculate the probability that a subject had their rash continue by taking that number (96) and dividing it by the total number of subjects (426). This gives us <span class="math inline">\(96/426=0.2254\)</span>. The other two probabilities are calculated similarly: take the total from the row or column, and divide by the total number of subjects (426).</p>
<p>The strategy we are deploying in the case of two by two tables has its equivalent in the strategies we are about to discuss using <em>truth tables</em>, and important tool in logic. We turn to that topic next.</p>
</div>
<div id="exercises-7" class="section level2 unnumbered">
<h2>Exercises</h2>
<ol style="list-style-type: decimal">
<li>Suppose your friend has a coin with heads on one side and tails on the other. You do not know, however, whether the coin is a fair coin. All you are told is what the supposed odds are for heads and tails. Recall that if odds in favor are n:m, then odds <em>against</em> are just the inverse, m:n. In addition, recall that rewards are calculated by using odds against. Your friend presents you with the following table with partial information (the odds are odds against):</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="center">Face</th>
<th align="center">Odds</th>
<th align="center">Implied.Prob</th>
<th align="center">Bet</th>
<th align="center">Payout</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Heads</td>
<td align="center">1:3</td>
<td align="center">X</td>
<td align="center">$12</td>
<td align="center">Z</td>
</tr>
<tr class="even">
<td align="center">Tails</td>
<td align="center">4:1</td>
<td align="center">Y</td>
<td align="center">$5</td>
<td align="center">W</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>What is X?</li>
<li>What is Y?</li>
<li>What is reward Z?</li>
<li>What is reward W?</li>
<li>Is it more likely that the coin will flip heads or tails?</li>
<li>What is the total of the implied probabilities (X+Y)?</li>
<li>Is your friend offering you a fair bet? Why or why not?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose this time we have a coin with a substantial flat edge so that sometimes it spins and stays on the edge without falling over. The coin is a fair coin in that heads and tails are equally likely, but now there is also a positive probability that the coin could land and stay on its edge. Suppose that the probabilities are given by the table below. Using this information, what are the odds supposed to be if you want to make sure that the wagers are fair? And consequently, what should the rewards be as part of the payouts?</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="center">Face</th>
<th align="center">Odds</th>
<th align="center">Implied.Prob</th>
<th align="center">Bet</th>
<th align="center">Payout</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Heads</td>
<td align="center">X</td>
<td align="center">0.4</td>
<td align="center">$12</td>
<td align="center">Z</td>
</tr>
<tr class="even">
<td align="center">Tails</td>
<td align="center">Y</td>
<td align="center">0.4</td>
<td align="center">$5</td>
<td align="center">W</td>
</tr>
<tr class="odd">
<td align="center">Edge</td>
<td align="center">V</td>
<td align="center">0.2</td>
<td align="center">$10</td>
<td align="center">U</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>What is X?</li>
<li>What is Y?</li>
<li>What is V?</li>
<li>What is reward Z?</li>
<li>What is reward W?</li>
<li>What is reward U?</li>
</ol>

</div>
</div>
<p style="text-align: center;">
<a href="intervention.html"><button class="btn btn-default">Previous</button></a>
<a href="probabilities-and-logic.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
